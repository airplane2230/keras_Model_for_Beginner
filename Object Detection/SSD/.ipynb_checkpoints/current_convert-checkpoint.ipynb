{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwzqBN-9-Crq"
   },
   "source": [
    "**Setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "khun5gBZ-B1G"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZNKk1C95XGB"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/voc_test')\n",
    "\n",
    "!pip install tensorflow==2.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYM9KoJi-dp5"
   },
   "source": [
    "# Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hq0Cc35n40t4"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "NUM_CLASSES = 21\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# path\n",
    "crack_pkl = './VOC/VOC2007.pkl'\n",
    "IMAGE_PATH = './VOC/images/'\n",
    "\n",
    "# .pkl에서 데이터를 불러옵니다.\n",
    "gt = pickle.load(open(crack_pkl, 'rb'))\n",
    "\n",
    "# gt의 key는 이미지 이름으로 이루어져 있습니다.\n",
    "# gt의 value_list는 이미지에 존재하는 객체 수로 이루어져 있다.\n",
    "# gt의 value는 총 24 길이로 이루어져 있는데,\n",
    "# 앞의 첫 4개 인덱스는 xmin, xmax, ymin, ymax 좌표입니다.\n",
    "# 나머지 20개는 클래스를 나타냅니다.\n",
    "keys = sorted(gt.keys())\n",
    "\n",
    "# 학습 및 검증 데이터를 8:2로 나누도록 하겠습니다.\n",
    "num_train = int(round(0.8 * len(keys)))\n",
    "\n",
    "# 3962\n",
    "train_keys = keys[:num_train]\n",
    "# 990\n",
    "val_keys = keys[num_train:]\n",
    "\n",
    "num_val = len(val_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zhl4c8sbA3fW"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 객체는 이미지(로드)와 레이블을 반환하도록 구성합니다.\n",
    "# 먼저, 이미지 경로와 해당 값을 리스트에 저장해두도록 하겠습니다.\n",
    "image_dir_list = list()\n",
    "value_list = list()\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "  image_dir_list.append(train_keys[i])\n",
    "  value_list.append(gt[train_keys[i]])\n",
    "\n",
    "image_dir_list = np.array(image_dir_list)\n",
    "value_list = np.array(value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAP0nKGRHtEa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_dir_ds = tf.data.Dataset.from_tensor_slices(image_dir_list)\n",
    "\n",
    "def get_imageLabel(image_dir):\n",
    "  image = tf.io.read_file(IMAGE_PATH + image_dir)\n",
    "  image = tf.image.decode_jpeg(image)\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  image = tf.image.resize(image, [224, 224])\n",
    "\n",
    "  return image\n",
    "  \n",
    "image_dir_ds = image_dir_ds.map(get_imageLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nOWk9vsxXu69"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 914
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1583655792883,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "dxXn7hytHtbg",
    "outputId": "937eb8f1-cc2f-43f0-d52f-6b037864a369"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000001.jpg\n",
      "tf.Tensor(\n",
      "[[[0.         0.00784314 0.        ]\n",
      "  [0.         0.00784314 0.        ]\n",
      "  [0.         0.00784314 0.        ]\n",
      "  ...\n",
      "  [0.00784314 0.01568628 0.01176471]\n",
      "  [0.00784314 0.01568628 0.01176471]\n",
      "  [0.00225854 0.01182193 0.00790036]]\n",
      "\n",
      " [[0.         0.00784314 0.        ]\n",
      "  [0.         0.00784314 0.        ]\n",
      "  [0.         0.00784314 0.        ]\n",
      "  ...\n",
      "  [0.01582528 0.02366842 0.01974685]\n",
      "  [0.01077799 0.01862112 0.01469956]\n",
      "  [0.00130068 0.00914382 0.00522225]]\n",
      "\n",
      " [[0.         0.00784314 0.        ]\n",
      "  [0.         0.00784314 0.        ]\n",
      "  [0.         0.00784314 0.        ]\n",
      "  ...\n",
      "  [0.01805985 0.02527273 0.01382315]\n",
      "  [0.0112843  0.01751523 0.01376951]\n",
      "  [0.00982129 0.007029   0.00126291]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.06534703 0.14953116 0.2963426 ]\n",
      "  [0.055067   0.11640386 0.2497711 ]\n",
      "  [0.14370213 0.20107439 0.3281971 ]\n",
      "  ...\n",
      "  [0.17512836 0.2965584  0.55971926]\n",
      "  [0.17289834 0.28666675 0.55163544]\n",
      "  [0.11623414 0.22536325 0.48612452]]\n",
      "\n",
      " [[0.13348113 0.19181946 0.34077775]\n",
      "  [0.13535313 0.20080952 0.32312196]\n",
      "  [0.02069291 0.09269299 0.22964863]\n",
      "  ...\n",
      "  [0.11839177 0.24688499 0.4917366 ]\n",
      "  [0.09346099 0.21788344 0.4496671 ]\n",
      "  [0.10911475 0.22117722 0.47234854]]\n",
      "\n",
      " [[0.04399942 0.09654257 0.23293038]\n",
      "  [0.17753418 0.23941633 0.36948603]\n",
      "  [0.09907219 0.16668424 0.3133404 ]\n",
      "  ...\n",
      "  [0.1465155  0.26961905 0.50792724]\n",
      "  [0.11802345 0.23959209 0.4631215 ]\n",
      "  [0.11077138 0.22074687 0.46768677]]], shape=(224, 224, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in image_dir_ds.take(1):\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vMPnKNOHtXM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmvbUZcdHtN-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jMhTyt5NHtL-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f5yfz5whHtHB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkwEsgP84lKp"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_list = None\n",
    "value_list = None\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    img = cv2.imread(os.path.join(IMAGE_PATH, train_keys[i]))\n",
    "    img = np.array(img, dtype = np.float64)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "    \n",
    "    values = np.expand_dims(gt[train_keys[i]], axis = 0)\n",
    "    if img_list is None:\n",
    "        img_list = img\n",
    "    else:\n",
    "        img_list = np.concatenate((img_list, img), axis = 0)\n",
    "    \n",
    "    if value_list is None:\n",
    "        value_list = values\n",
    "    else:\n",
    "        value_list.append(np.array(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTLEyeVJ4lKs"
   },
   "source": [
    "# Model define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1942,
     "status": "ok",
     "timestamp": 1571413917921,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "3C7ehdcv4lKs",
    "outputId": "3bad3d5c-46f8-467e-8214-e2929947f3e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6maq771w4lKu"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class PriorBox(Layer):\n",
    "    def __init__(self, s_min = None, s_max = None,\n",
    "                 feature_map_number = None, num_box = None ,**kwargs):\n",
    "        '''\n",
    "\n",
    "        :param img_size:\n",
    "        :param s_min:\n",
    "        :param s_max:\n",
    "        :param feature_map_number: [1, 2, 3, 4, 5, 6]\n",
    "        '''\n",
    "\n",
    "        self.default_boxes = []\n",
    "        self.num_box = num_box\n",
    "        if s_min <= 0:\n",
    "            raise Exception('min_size must be positive')\n",
    "        self.s_min = s_min\n",
    "        self.s_max = s_max\n",
    "        self.feature_map_number = feature_map_number\n",
    "        self.aspect_ratio = [[1., 1/1, 2., 1/2],\n",
    "                             [1., 1/1, 2., 1/2],\n",
    "                             [1., 1/1, 2., 1/2, 3., 1/3],\n",
    "                             [1., 1/1, 2., 1/2, 3., 1/3],\n",
    "                             [1., 1/1, 2., 1/2, 3., 1/3],\n",
    "                             [1., 1/1, 2., 1/2]]\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.batch_size = input_shape[0]\n",
    "        self.width = input_shape[2]\n",
    "        self.height = input_shape[1]\n",
    "        \n",
    "        self.s_k = self.get_sk(self.s_max, self.s_min, 6, self.feature_map_number)\n",
    "        self.s_k1 = self.get_sk(self.s_max, self.s_min, 6, self.feature_map_number + 1)  \n",
    "        \n",
    "        super(PriorBox, self).build(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1] * input_shape[2], 4)\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        feature_map_ratio = self.aspect_ratio[self.feature_map_number - 1]\n",
    "        s = 0.0\n",
    "        \n",
    "        print(x.shape[0])\n",
    "\n",
    "        default_boxes = None\n",
    "        for eleh in range(self.height):\n",
    "            center_y = (eleh + 0.5) / float(self.height)\n",
    "            for elew in range(self.width):\n",
    "                center_x = (elew + 0.5) / float(self.width)\n",
    "                for ratio in feature_map_ratio:\n",
    "                    s = self.s_k\n",
    "\n",
    "                    if(ratio == 1.0):\n",
    "                        s = np.sqrt(self.s_k * self.s_k1)\n",
    "\n",
    "                    box_width = s * np.sqrt(ratio)\n",
    "                    box_height = s / np.sqrt(ratio)\n",
    "                    \n",
    "                    if default_boxes is None:\n",
    "                        default_boxes = np.array([center_x, center_y, box_width, box_height]).reshape(-1, 4)\n",
    "                    else:\n",
    "                        default_boxes = np.concatenate((default_boxes, np.array([[center_x, center_y, box_width, box_height]])), axis = 0)\n",
    "        \n",
    "        boxes_tensor = np.expand_dims(default_boxes, axis = 0)\n",
    "        boxes_tensor = tf.tile(tf.constant(boxes_tensor, dtype='float32'), (tf.shape(x)[0], 1, 1))\n",
    "        \n",
    "        return boxes_tensor\n",
    "\n",
    "    def get_sk(self, s_max, s_min, m, k):\n",
    "        '''\n",
    "        :param s_max:\n",
    "        :param s_min:\n",
    "        :param m: number of feature map\n",
    "        :param k: k-th feature map\n",
    "        :return:\n",
    "        '''\n",
    "        sk_value = s_min + ((s_max - s_min) / (m - 1.0)) * (k - 1)\n",
    "\n",
    "        return sk_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c_MDOsPL4lKx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Flatten, add, Activation, Concatenate\n",
    "from tensorflow.keras.layers import Input, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def _conv_block(input_tensor, s,\n",
    "                c, n, t, stage):\n",
    "    # s : strides\n",
    "    # c : channel\n",
    "    # n : iter\n",
    "    # t : factor\n",
    "\n",
    "    conv_name_base = 'res' + str(stage) + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + '_branch'\n",
    "    x = None\n",
    "\n",
    "    # Strides == 1 block\n",
    "    if (s == 1):\n",
    "        shortcut = None\n",
    "        for i in range(n):\n",
    "            x = Conv2D(c, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a_' + str(i))(input_tensor)\n",
    "            x = BatchNormalization(name=bn_name_base + '2a_' + str(i))(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = DepthwiseConv2D((3, 3), depth_multiplier=t, padding='same', name=conv_name_base + '2bdepth_' + str(i))(\n",
    "                x)\n",
    "            x = BatchNormalization(name=bn_name_base + '2b_' + str(i))(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Conv2D(c, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c_' + str(i))(x)\n",
    "            x = BatchNormalization(name=bn_name_base + '2c_' + str(i))(x)\n",
    "            x = Activation('linear')(x)\n",
    "\n",
    "            if (shortcut is None):\n",
    "                shortcut = Conv2D(c, (1, 1), strides=s, padding='same', kernel_initializer='he_normal',\n",
    "                                  name=conv_name_base + '1_' + str(i))(input_tensor)\n",
    "            else:\n",
    "                shortcut = Conv2D(c, (1, 1), strides=s, padding='same', kernel_initializer='he_normal',\n",
    "                                  name=conv_name_base + '1_' + str(i))(x)\n",
    "\n",
    "            x = add([x, shortcut], name='c_add_' + str(stage) + '_' + str(i))\n",
    "    # Strides == 2 block\n",
    "    elif (s == 2):\n",
    "        for i in range(n):\n",
    "            x = Conv2D(c, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2a_' + str(i))(input_tensor)\n",
    "            x = BatchNormalization(name=bn_name_base + '2a_' + str(i))(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = DepthwiseConv2D((3, 3), strides=s, depth_multiplier=t, padding='same',\n",
    "                                name=conv_name_base + '2bdepth_' + str(i))(x)\n",
    "            x = BatchNormalization(name=bn_name_base + '2b_' + str(i))(x)\n",
    "            x = Activation('relu')(x)\n",
    "            x = Conv2D(c, (1, 1), kernel_initializer='he_normal', name=conv_name_base + '2c_' + str(i))(x)\n",
    "            x = BatchNormalization(name=bn_name_base + '2c_' + str(i))(x)\n",
    "            x = Activation('linear')(x)\n",
    "    return x\n",
    "\n",
    "def _SSD_Conv_fc(x, filter, kernel_size, strides = (1, 1)):\n",
    "    net = Conv2D(filter, kernel_size = kernel_size, strides = strides)(x)\n",
    "    x = BatchNormalization()(net)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    print(x.shape, 'SSD_Conv_fc')\n",
    "\n",
    "    return x, net\n",
    "\n",
    "def _SSD_Conv(x, filter, kernel_size, strides):\n",
    "    x = Conv2D(filter // 2, kernel_size = (1, 1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = DepthwiseConv2D(kernel_size=kernel_size, strides = strides, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    net = Conv2D(filter, (1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(net)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    print(x.shape, 'SSD_Conv')\n",
    "\n",
    "    return x, net\n",
    "\n",
    "def _detections(x, feature_map_num, bbox_num, min_s, max_s, num_classes):\n",
    "    # bbox location\n",
    "    mbox_loc = Conv2D(bbox_num * 4, (3, 3), padding='same', name=str(feature_map_num) + '_mbox_loc')(x)\n",
    "    mbox_loc_flat = Flatten(name = str(feature_map_num) + '_mbox_loc_flat')(mbox_loc)\n",
    "\n",
    "    # class confidence\n",
    "    mbox_conf = Conv2D(bbox_num * num_classes, (3, 3), padding = 'same', name = str(feature_map_num) + '_mbox_conf')(x)\n",
    "    mbox_conf_flat = Flatten(name = str(feature_map_num) + '_mbox_conf_flat')(mbox_conf)\n",
    "\n",
    "    # Anchor box candidate\n",
    "    mbox_priorbox = PriorBox(min_s, max_s, feature_map_num, bbox_num, name = str(feature_map_num) + 'mbox_prior_box')(x)\n",
    "\n",
    "    return mbox_loc_flat, mbox_conf_flat, mbox_priorbox\n",
    "\n",
    "def SSD(input_shape, num_classes):\n",
    "    img_input = Input(shape=input_shape)\n",
    "\n",
    "    # MobileNetV2\n",
    "    # init\n",
    "    print('init')\n",
    "    x = Conv2D(32, kernel_size=(3, 3), strides=(2, 2), padding='same', \n",
    "               kernel_initializer='he_normal', name='conv1')(img_input)  # (112, 112, 32)\n",
    "\n",
    "    mobile_conv1 = _conv_block(x, c=16, s=1, n=1, t=1, stage=2)  # (112, 112, 16)\n",
    "    mobile_conv2 = _conv_block(mobile_conv1, c=24, s=2, n=2, t=6, stage=3)  # (56, 56, 24)\n",
    "    mobile_conv3 = _conv_block(mobile_conv2, c=32, s=2, n=3, t=6, stage=4)  # (28, 28, 32)\n",
    "    mobile_conv4 = _conv_block(mobile_conv3, c=64, s=2, n=3, t=6, stage=5)  # (14, 14, 64)\n",
    "    mobile_conv5 = _conv_block(mobile_conv4, c=160, s=1, n=4, t=6, stage=6)  # (14, 14, 96)\n",
    "    mobile_conv6 = _conv_block(mobile_conv5, c=160, s=2, n=3, t=6, stage=7)  # (7, 7, 160)\n",
    "    mobile_conv7 = _conv_block(mobile_conv6, c=320, s=1, n=1, t=6, stage=8)  # (7, 7, 320)\n",
    "\n",
    "    fc6, fc6_for_feature = _SSD_Conv_fc(mobile_conv7, 1024, kernel_size = (3, 3), strides=(2, 2))\n",
    "    fc7, fc7_for_feature = _SSD_Conv_fc(fc6, 1024, kernel_size= (1, 1))\n",
    "    conv8_2, conv8_2_for_feature = _SSD_Conv(fc7, 512, kernel_size=(3, 3), strides = (2, 2))\n",
    "    conv9_2, conv9_2_for_feature = _SSD_Conv(conv8_2, 512, kernel_size=(3, 3), strides = (1, 1))\n",
    "    conv10_2, conv10_2_for_feature = _SSD_Conv(conv9_2, 512, kernel_size=(3, 3), strides = (1, 1))\n",
    "\n",
    "    clf1_mbox_loc_flat, clf1_mbox_conf_flat, clf1_mbox_priorbox = _detections(mobile_conv4, 1, 4, 0.2, 0.9, num_classes)\n",
    "    clf2_mbox_loc_flat, clf2_mbox_conf_flat, clf2_mbox_priorbox = _detections(fc6_for_feature, 2, 4, 0.2, 0.9, num_classes)\n",
    "    clf3_mbox_loc_flat, clf3_mbox_conf_flat, clf3_mbox_priorbox = _detections(fc7_for_feature, 3, 6, 0.2, 0.9, num_classes)\n",
    "    clf4_mbox_loc_flat, clf4_mbox_conf_flat, clf4_mbox_priorbox = _detections(conv8_2_for_feature, 4, 6, 0.2, 0.9, num_classes)\n",
    "    clf5_mbox_loc_flat, clf5_mbox_conf_flat, clf5_mbox_priorbox = _detections(conv9_2_for_feature, 5, 6, 0.2, 0.9, num_classes)\n",
    "    clf6_mbox_loc_flat, clf6_mbox_conf_flat, clf6_mbox_priorbox = _detections(conv10_2_for_feature, 6, 4, 0.2, 0.9, num_classes)\n",
    "\n",
    "    mbox_loc = Concatenate(axis = 1, name = 'mbox_loc')([clf1_mbox_loc_flat, clf2_mbox_loc_flat,\n",
    "                            clf3_mbox_loc_flat, clf4_mbox_loc_flat,\n",
    "                            clf5_mbox_loc_flat, clf6_mbox_loc_flat])\n",
    "    mbox_conf = Concatenate(axis = 1, name = 'mbox_conf')([clf1_mbox_conf_flat, clf2_mbox_conf_flat,\n",
    "                                                           clf3_mbox_conf_flat, clf4_mbox_conf_flat,\n",
    "                                                           clf5_mbox_conf_flat, clf6_mbox_conf_flat])\n",
    "    mbox_priorbox = Concatenate(axis = 1, name = 'mbox_priorbox')([clf1_mbox_priorbox, clf2_mbox_priorbox,\n",
    "                                                                   clf3_mbox_priorbox, clf4_mbox_priorbox,\n",
    "                                                                   clf5_mbox_priorbox, clf6_mbox_priorbox])\n",
    "    \n",
    "    print('Brfore Reshape', mbox_loc.shape, mbox_conf.shape, mbox_priorbox.shape)\n",
    "    \n",
    "    num_boxes = mbox_loc.shape[-1] // 4\n",
    "\n",
    "    mbox_loc = Reshape((num_boxes, 4), name = 'mbox_loc_final')(mbox_loc)\n",
    "    mbox_conf = Reshape((num_boxes, num_classes), name = 'mbox_conf_logits')(mbox_conf)\n",
    "    mbox_conf = Activation('softmax', name = 'mbox_conf_final')(mbox_conf)\n",
    "    print('After Reshape', mbox_loc.shape, mbox_conf.shape, mbox_priorbox.shape)\n",
    "\n",
    "    predictions = Concatenate(axis = 2, name = 'predictions')([mbox_loc, mbox_conf, mbox_priorbox])\n",
    "    print('predictions shape ', predictions.shape)\n",
    "\n",
    "    model = Model(inputs = img_input, outputs = predictions)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LXfObpgF-TqJ"
   },
   "source": [
    "# Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6163,
     "status": "ok",
     "timestamp": 1571413925804,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "_kxy83sJ4lKz",
    "outputId": "5d03e934-7a7c-432a-f644-9f8e2e711398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init\n",
      "(None, 3, 3, 1024) SSD_Conv_fc\n",
      "(None, 3, 3, 1024) SSD_Conv_fc\n",
      "(None, 2, 2, 512) SSD_Conv\n",
      "(None, 2, 2, 512) SSD_Conv\n",
      "(None, 2, 2, 512) SSD_Conv\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "Brfore Reshape (None, 3752) (None, 19698) (None, 938, 4)\n",
      "After Reshape (None, 938, 4) (None, 938, 21) (None, 938, 4)\n",
      "predictions shape  (None, 938, 29)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "model = SSD(input_shape, num_classes = 21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6mSNUiK584rI"
   },
   "source": [
    "# computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BrFP4uuN9OQ8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def intersection(rect1, rect2):\n",
    "    \"\"\"\n",
    "    intersecton of units\n",
    "    compute boarder line top, left, right and bottom.\n",
    "    rect is defined as [ top_left_x, top_left_y, width, height ]\n",
    "    \"\"\"\n",
    "    top = np.max(rect1[1], rect2[1])\n",
    "    left = np.max(rect1[0], rect2[0])\n",
    "    right = np.min(rect1[0] + rect1[2], rect2[0] + rect2[2])\n",
    "    bottom = np.min(rect1[1] + rect1[3], rect2[1] + rect2[3])\n",
    "\n",
    "    result = tf.where(tf.math.logical_and(tf.greater(bottom, top), tf.greater(right, left)), (bottom-top)*(right-left), 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def jaccard(rect1, rect2):\n",
    "    \"\"\"\n",
    "    Jaccard index.\n",
    "    Jaccard index is defined as #(A∧B) / #(A∨B)\n",
    "    \n",
    "    len_rect1 : 4\n",
    "    len_rect2 : 4\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # len_rect1_ : 4, len_rect2_ : 4\n",
    "    rect1_ = []\n",
    "    for i in range(len(rect1)):\n",
    "        cond_value = tf.where(rect1[i] >= 0, rect1[i], 0)\n",
    "        rect1_.append(cond_value)\n",
    "            \n",
    "    rect2_ = []\n",
    "    for i in range(len(rect2)):\n",
    "        cond_value = tf.where(rect2[i] >= 0, rect2[i], 0)\n",
    "        rect2_.append(cond_value)\n",
    "    \n",
    "    s = tf.add(tf.multiply(rect1_[2], rect1_[3]), tf.multiply(rect2_[2], rect2_[3]))\n",
    "\n",
    "    # rect1 and rect2 => A∧B\n",
    "    intersect = intersection(rect1_, rect2_)\n",
    "\n",
    "    # rect1 or rect2 => A∨B\n",
    "    union = s - intersect\n",
    "\n",
    "    # A∧B / A∨B\n",
    "    return tf.divide(intersect, union)\n",
    "\n",
    "\n",
    "def corner2center(rect):\n",
    "    \"\"\"\n",
    "    rect is defined as [ top_left_x, top_left_y, width, height ]\n",
    "    \"\"\"\n",
    "    center_x = (2 * rect[0] + rect[2]) * 0.5\n",
    "    center_y = (2 * rect[1] + rect[3]) * 0.5\n",
    "\n",
    "    return tf.stack([center_x, center_y, abs(rect[2]), abs(rect[3])])\n",
    "\n",
    "\n",
    "def center2corner(rect):\n",
    "    \"\"\"\n",
    "    rect is defined as [ top_left_x, top_left_y, width, height ]\n",
    "    \"\"\"\n",
    "    corner_x = rect[0] - rect[2] * 0.5\n",
    "    corner_y = rect[1] - rect[3] * 0.5\n",
    "\n",
    "    return tf.stack([corner_x, corner_y, tf.math.abs(rect[:, 2]), tf.amth.abs(rect[:, 3])])\n",
    "\n",
    "\n",
    "def convert2diagonal_points(rect):\n",
    "    \"\"\"\n",
    "    convert rect format\n",
    "    Args:\n",
    "        input format is...\n",
    "        [ top_left_x, top_left_y, width, height ]\n",
    "    Returns:\n",
    "        output format is...\n",
    "        [ top_left_x, top_left_y, bottom_right_x, bottom_right_y ]\n",
    "    \"\"\"\n",
    "    return [rect[0], rect[1], rect[0]+rect[2], rect[1]+rect[3]]\n",
    "\n",
    "\n",
    "def convert2wh(rect):\n",
    "    \"\"\"\n",
    "    convert rect format\n",
    "    Args:\n",
    "        input format is...\n",
    "        [ top_left_x, top_left_y, bottom_right_x, bottom_right_y ]\n",
    "    Returns:\n",
    "        output format is...\n",
    "        [ top_left_x, top_left_y, width, height ]\n",
    "    \"\"\"\n",
    "    result = tf.stack([rect[0], rect[1], rect[2] - rect[0], rect[3]-rect[1]])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cmjLnjHI9aiy"
   },
   "source": [
    "# MultiBoxLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIDa0Wp09FDe"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "class MultiboxLoss(object):\n",
    "    '''\n",
    "        loss func defiend as Loss = (Loss_conf + a * Loss_loc) / N\n",
    "        need for total loss.\n",
    "\n",
    "        Need list:\n",
    "            confidence loss\n",
    "            location loss\n",
    "            positive list\n",
    "            negative list\n",
    "    '''\n",
    "\n",
    "    def __init__(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    # bbox 의 loc에 대한 loss 계산\n",
    "    def _smooth_L1_Loss(self, y_true, y_pred, pos):\n",
    "        abs_loss = tf.abs(y_true - y_pred)\n",
    "        sq_loss = 0.5 * (y_true - y_pred) ** 2\n",
    "        l1_loss = tf.where(tf.less(abs_loss, 1.0), sq_loss, abs_loss - 0.5)\n",
    "\n",
    "        # shape : [?, num_boxes, 4] -> [?, num_boxes]\n",
    "        return tf.reduce_sum(l1_loss, axis=-1) * pos\n",
    "\n",
    "    # bbox의 class에 대한 loss 계산\n",
    "    def _softmax_Loss(self, y_true, y_pred, pos, neg):\n",
    "        y_pred = tf.maximum(tf.minimum(y_pred, 1 - 1e-15), 1e-15)\n",
    "\n",
    "        # positive는 IOU를 합격한 박스 1 또는 0\n",
    "        # 맞춘 만큼 loss값을 감소시킴.\n",
    "        pos_loss = (tf.log(tf.exp(y_pred) / (tf.reduce_sum(tf.exp(y_pred), axis=-1))))\n",
    "\n",
    "        # IOU는 불합격했지만, 클래스가 있을 확률이 높은 박스 1 또는 0\n",
    "        # 맞춘 만큼 loss를 감소시킴\n",
    "        neg_loss = tf.log(y_pred)\n",
    "\n",
    "        softmax_loss = -tf.reduce_sum((y_true * (pos_loss + neg_loss)), axis = - 1) * (pos + neg)\n",
    "\n",
    "        return softmax_loss\n",
    "\n",
    "    # total_loss 계산\n",
    "    def comute_loss(self, y_true, y_pred):\n",
    "        \"\"\" Compute multibox loss\n",
    "        # Arguments\n",
    "            @y_true:\n",
    "                tensor of shape (?, num_object, 4 + 4) -> [?, ?, 8]\n",
    "            @y_pred:\n",
    "                tensor of shape(?, num_boxes, 4 + num_classes(4) + 4)\n",
    "\n",
    "            @class_num = 4\n",
    "\n",
    "            @configration of y_pred + y_true:\n",
    "                y_pred[:, :, :4]:\n",
    "                    bbox_loc\n",
    "                y_pred[:, :, 4:8]:\n",
    "                    class_confidence\n",
    "                y_pred[:, :, 10:]:\n",
    "                    mbox_priorbox(cx, cy, w, h)\n",
    "        \"\"\"\n",
    "        # y_true class : <class 'tensorflow.python.framework.ops.Tensor'>\n",
    "        default_boxes = y_pred[:, :, -4:] # default_boxes shape : (8, 938, 4) --> 8 is batch_size\n",
    "        \n",
    "        positives = []\n",
    "        negatives = []\n",
    "        ex_gt_labels = []\n",
    "        ex_gt_boxes = []\n",
    "        \n",
    "        num_boxes = y_pred.shape[1]\n",
    "        matcher = Matcher(num_boxes, default_boxes)\n",
    "        print('make Matcher=======================')\n",
    "        actual_locs = []\n",
    "        actual_labels = []\n",
    "        for i in range(self.batch_size):\n",
    "          # y_true[i][:, :, :4], [-1, 4] --> (i, num_box, 4)\n",
    "          # tf.reshape(y_true[i][:, :, :4], [-1, 4]) --> (num_box, 4)\n",
    "          locs = tf.reshape(y_true[i][:, :, :4], [-1, 4])\n",
    "          labels = tf.argmax(y_true[i][:, :, 4:], axis = -1) # (1, num_box)\n",
    "          labels = tf.reshape(labels, [-1]) # (num_box, )\n",
    "          for i in range(len(locs)):\n",
    "            loc = locs[i] # loc : Tensor(\"TensorArrayV2Read/TensorListGetItem:0\", shape=(4,), dtype=float32)\n",
    "            loc = convert2wh(loc)\n",
    "            loc = corner2center(loc) # Tensor(\"PartitionedCall_1:0\", shape=(4,), dtype=float32)\n",
    "            actual_locs.append(loc)\n",
    "                \n",
    "          for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            actual_labels.append(labels)\n",
    "            \n",
    "          pred_locs = y_pred[i][:, :4] # <class 'tensorflow.python.framework.ops.Tensor'> (938, 4)\n",
    "          pred_confs = y_pred[i][:, 4:-4] # <class 'tensorflow.python.framework.ops.Tensor'> (938, 25)\n",
    "          \n",
    "          print('go in matcher.matching#####')\n",
    "          pos_list, neg_list, t_gtl, t_gtb = matcher.matching(pred_confs, pred_locs, actual_labels, actual_locs, i)\n",
    "          positives.append(pos_list) # (?, default_box_num_pos)\n",
    "          negatives.append(neg_list) # (?, default_box_num_neg)\n",
    "          ex_gt_labels.append(t_gtl) # (?, default_box_num_label)\n",
    "          ex_gt_boxes.append(t_gtb)  # (?, default_box_num, loc)\n",
    "\n",
    "        ex_gt_labels_to_categorical = to_categorical(ex_gt_labels)\n",
    "        # 클래스에 대한 손실 함수\n",
    "        conf_loss = self._softmax_Loss(ex_gt_labels_to_categorical,\n",
    "                                       y_pred[:, :, 4:8],\n",
    "                                       positives, negatives)  # [?, 984]\n",
    "\n",
    "        # 박스 위치에 대한 손실 함수\n",
    "        loc_loss = self._smooth_L1_Loss(y_true[:, :, :4],\n",
    "                                        y_pred[:, :, 4], positives)  # [?, 984]\n",
    "\n",
    "        total_loss = tf.reduce_sum(conf_loss + loc_loss)\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1IbF-08w9epJ"
   },
   "source": [
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ff5v5yZ59ubW"
   },
   "outputs": [],
   "source": [
    "classes = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fVhjkjJl9JgJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Matcher:\n",
    "    \n",
    "    def __init__(self, num_boxes, default_boxes):\n",
    "        \"\"\"\n",
    "                initializer require feature-map shapes and default boxes\n",
    "                Args:\n",
    "                    fmap_shapes: feature-map's shape\n",
    "                    default_boxes: generated default boxes\n",
    "                \"\"\"\n",
    "        self.num_boxes = num_boxes\n",
    "        self.default_boxes = default_boxes\n",
    "    \n",
    "    def matching(self, pred_confs, pred_locs, actual_labels, actual_locs, batch_size):\n",
    "        \"\"\"\n",
    "                match default boxes and bouding boxes.\n",
    "                matching computes pos and neg count for the computation of loss.\n",
    "                now, the most noting point is that it is not important that\n",
    "                whether class label is correctly predicted.\n",
    "                class label loss is evaled by loss_conf\n",
    "                matches variable have some Box instance and most of None.\n",
    "                if jaccard >= 0.5, that matches box has Box(gt_loc, gt_label).\n",
    "                then, sort by pred_confs loss and extract 3*pos boxes, which they\n",
    "                have Box([], classes) => background.\n",
    "                when compute losses, we need transformed ground truth labels and locations\n",
    "                because each box has self confidence and location.\n",
    "                so, we should prepare expanded labels and locations whose size is as same as len(matches).\n",
    "                Args:\n",
    "                    pred_confs: predicated confidences\n",
    "                    pred_locs: predicated locations\n",
    "                    actual_labels: answer class labels\n",
    "                    actual_locs: answer box locations\n",
    "                Returns:\n",
    "                    postive_list: if pos -> 1 else -> 0\n",
    "                    negative_list: if neg and label is not classes(not unknown class) 1 else 0\n",
    "                    expanded_gt_labels: gt_label if pos else classes\n",
    "                    expanded_gt_locs: gt_locs if pos else [0, 0, 0, 0]\n",
    "        \"\"\"\n",
    "        self.pos = 0\n",
    "        self.neg = 0\n",
    "        pos_list = []\n",
    "        neg_list = []\n",
    "        expanded_gt_labels = []\n",
    "        expanded_gt_locs = []\n",
    "        \n",
    "        matches = []\n",
    "        matched = []\n",
    "        # pred_confs.shsape, pred_locs.shape, len(actual_locs), len(actual_labels)\n",
    "        # (938, 21) (938, 4) 2 2\n",
    "        print('In Matcher1!===============================')\n",
    "        for _ in range(self.num_boxes):\n",
    "            matches.append(None) # len is 938\n",
    "            \n",
    "        \n",
    "        \n",
    "        test_int = 0\n",
    "        for gt_label, gt_box in zip(actual_labels, actual_locs):\n",
    "          for i in range(len(matches)):\n",
    "            # jacc : Tensor(\"PartitionedCall:0\", shape=(), dtype=float64) () <class 'tensorflow.python.framework.ops.Tensor'>\n",
    "            jacc = jaccard(gt_box, self.default_boxes[batch_size, i]) # self.default_boxes[batch_size, i] -> (4, )\n",
    "            if(tf.math.greater_equal(jacc, 0.5)):\n",
    "              matches[i] = 4\n",
    "              self.pos += 1\n",
    "              matched.append(gt_label)\n",
    "\n",
    "        print('In Matcher2!===============================')\n",
    "\n",
    "        # neg, pos 비율 값\n",
    "        neg_pos = 5\n",
    "\n",
    "        max_length = tf.multiply(neg_pos, self.pos)\n",
    "\n",
    "        loss_confs = []\n",
    "        loss_conf_cnt = 0\n",
    "\n",
    "        # pred_confs.shape : (938, 21)\n",
    "        # 각 default box의 confidence에 대해서\n",
    "        for i in range(pred_confs.get_shape()[0]):\n",
    "            pred_conf = pred_confs[i] # (21, )\n",
    "            # 각 예측 값을 소프트 맥스함수를 통해 해당 클래스 인덱스로 치환한다.\n",
    "            # (num_box, num_class) -> (num_box, )\n",
    "            pred = tf.reduce_max(tf.divide(tf.math.exp(pred_conf), (tf.reduce_sum(tf.math.exp(pred_conf)) + 1e-5))) # (), Tensor\n",
    "            loss_confs.append(pred)\n",
    "            loss_conf_cnt += 1\n",
    "            \n",
    "        # loss_conf_cnt : 938, int\n",
    "        # max_length : tf.multimul(:)\n",
    "        \n",
    "        size = tf.math.minimum(loss_conf_cnt, neg_pos * self.pos) # Tensor(\"Minimum:0\", shape=(), dtype=int32)\n",
    "        \n",
    "        # TopKV2(values=<tf.Tensor 'TopKV2:0' shape=(None,) dtype=float64>, indices=<tf.Tensor 'TopKV2:1' shape=(None,) dtype=int32>)\n",
    "        indices = tf.math.top_k(loss_confs, size) # class : <clas`s 'tensorflow.python.ops.gen_nn_ops.TopKV2'>\n",
    "        indice_values = indices[1]\n",
    "        print(indice_values.__class__, indice_values.dtype, indice_values.shape, indice_values)\n",
    "        print('In Matcher3!===============================')\n",
    "\n",
    "        for i in range(indice_values.get_shape()[0]):\n",
    "          # i : 0 ~\n",
    "          temp_index = indice_values[i]\n",
    "          print(temp_index, 'temp_index')\n",
    "\n",
    "          # negative를 적당히 사용해야 되는데,\n",
    "          # positive * neg_pos 비율보다 높으면 좋지 않으므로 break 시킨다.\n",
    "          if self.neg > self.pos * neg_pos:\n",
    "              break\n",
    "\n",
    "          maches_index = tf.gather(matches, temp_index)\n",
    "          pred_confs_index = tf.gather(pred_confs, temp_index)\n",
    "          pred_conf = tf.argmax(pred_confs_index)\n",
    "\n",
    "          # classes - 1은 배경을 의미함.\n",
    "          # 박스가 안겹치면서 배경이 아닌 경우\n",
    "          # False Negative -> 박스가 없다고 판단했지만 객체가 있을 수도 있는 부분 -하종우\n",
    "          if(matches_index is None and (classes - 1 != pred_conf)):\n",
    "              matches[temp_index] = 1\n",
    "              self.neg += 1\n",
    "                \n",
    "        print('In Matcher4!===============================')\n",
    "\n",
    "        # matches는 None이거나 Box instance가 들어있는 array이다.\n",
    "        for box in matches:\n",
    "            # 박스가 없으면\n",
    "            if box is None:\n",
    "                pos_list.append(0)\n",
    "                neg_list.append(0)\n",
    "                expanded_gt_labels.append(classes - 1)\n",
    "                expanded_gt_locs.append([0] * 4)\n",
    "            # False Negative 부분\n",
    "            elif(0 == len(box.loc)):\n",
    "                pos_list.append(0)\n",
    "                neg_list.append(1)\n",
    "                expanded_gt_labels.append(classes - 1)\n",
    "                expanded_gt_locs.append([0] * 4)\n",
    "            # 박스가 존재한다면\n",
    "            else:\n",
    "                pos_list.append(1)\n",
    "                neg_list.append(0)\n",
    "                expanded_gt_labels.append(box.index)\n",
    "                expanded_gt_locs.append(box.loc)\n",
    "\n",
    "        return pos_list, neg_list, expanded_gt_labels, expanded_gt_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CjxilNoN9iKf"
   },
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sB1APO8EQx7l"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1372,
     "status": "ok",
     "timestamp": 1571411426397,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "TiQ_NG7A4lK1",
    "outputId": "d2e9360b-2feb-427c-e49b-db7c0de4b960"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer conv1 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "test_pred = model(img_list) # [batch_size, 938, 29]\n",
    "test_pred = tf.cast(test_pred, tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1087,
     "status": "error",
     "timestamp": 1571411435065,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "w2NPln6q4lK6",
    "outputId": "02c4aef6-8e65-48d1-b4f1-41a0631477a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make Matcher=======================\n",
      "go in matcher.matching#####\n",
      "In Matcher1!===============================\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-875cd16d1fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-5d420943ea4e>\u001b[0m in \u001b[0;36mcomute_loss\u001b[0;34m(self, y_true, y_pred)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'go in matcher.matching#####'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m           \u001b[0mpos_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_gtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_gtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_confs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m           \u001b[0mpositives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (?, default_box_num_pos)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m           \u001b[0mnegatives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (?, default_box_num_neg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-3efa6fbb5820>\u001b[0m in \u001b[0;36mmatching\u001b[0;34m(self, pred_confs, pred_locs, actual_labels, actual_locs, batch_size)\u001b[0m\n\u001b[1;32m     59\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;31m# jacc : Tensor(\"PartitionedCall:0\", shape=(), dtype=float64) () <class 'tensorflow.python.framework.ops.Tensor'>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mjacc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjaccard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# self.default_boxes[batch_size, i] -> (4, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgreater_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m               \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-10534cf0e2e9>\u001b[0m in \u001b[0;36mjaccard\u001b[0;34m(rect1, rect2)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# rect1 and rect2 => A∧B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mintersect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect1_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect2_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# rect1 or rect2 => A∨B\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-10534cf0e2e9>\u001b[0m in \u001b[0;36mintersection\u001b[0;34m(rect1, rect2)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrect1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrect2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mbottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrect1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrect2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m   2616\u001b[0m     \"\"\"\n\u001b[1;32m   2617\u001b[0m     return _wrapreduction(a, np.minimum, 'min', axis, None, out, keepdims=keepdims,\n\u001b[0;32m-> 2618\u001b[0;31m                           initial=initial)\n\u001b[0m\u001b[1;32m   2619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "loss_fn = MultiboxLoss(NUM_CLASSES)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    logits = model(img_list)\n",
    "    \n",
    "    loss = loss_fn.comute_loss(value_list, test_pred.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TOo_Y41li6Wq"
   },
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1570431859963,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "p4lwQSDqCBl7",
    "outputId": "737627eb-c7e8-4eac-a902-ef1561843251"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection==================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=90638, shape=(), dtype=float64, numpy=0.0>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1700,
     "status": "ok",
     "timestamp": 1570432182974,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "vnt1-taTAvDU",
    "outputId": "d53b5eb8-8cef-4447-c20a-dafda2361a07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intersection==================================\n",
      "Tensor(\"cond_9/Identity:0\", shape=(), dtype=int32)\n",
      "Tensor(\"mul:0\", shape=(), dtype=int32)\n",
      "Tensor(\"placeholder:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "@tf.function\n",
    "def intersection(rect1, rect2):\n",
    "    print('intersection==================================')\n",
    "    top = tf.math.maximum(rect1[1], rect2[1])\n",
    "    left = tf.math.maximum(rect1[0], rect2[0])\n",
    "    right = tf.math.minimum(rect1[0] + rect1[2], rect2[0] + rect2[2])\n",
    "    bottom = tf.math.minimum(rect1[1] + rect1[3], rect2[1] + rect2[3])\n",
    "\n",
    "    result = tf.where(tf.math.logical_and(tf.greater(bottom, top), tf.greater(right, left)), (bottom-top)*(right-left), 0)\n",
    "\n",
    "    return result\n",
    "\n",
    "@tf.function\n",
    "def jaccard(rect1, rect2):\n",
    "    # len_rect1_ : 4, len_rect2_ : 4\n",
    "    rect1_ = []\n",
    "    for i in range(len(rect1)):\n",
    "        cond_value = tf.where(rect1[i] >= 0, rect1[i], 0)\n",
    "        rect1_.append(cond_value)\n",
    "            \n",
    "    rect2_ = []\n",
    "    for i in range(len(rect2)):\n",
    "        cond_value = tf.where(rect2[i] >= 0, rect2[i], 0)\n",
    "        rect2_.append(cond_value)\n",
    "    \n",
    "    s = tf.add(tf.multiply(rect1_[2], rect1_[3]), tf.multiply(rect2_[2], rect2_[3]))\n",
    "    # rect1 and rect2 => A∧B\n",
    "    intersect = intersection(rect1_, rect2_)\n",
    "    # rect1 or rect2 => A∨B\n",
    "    union = s - intersect\n",
    "    # A∧B / A∨B\n",
    "    return tf.divide(intersect, union)\n",
    "\n",
    "@tf.function\n",
    "def test():\n",
    "  number = 0\n",
    "  \n",
    "  jacc = jaccard([10, 10, 10, 10], [20, 20, 20, 20])\n",
    "  \n",
    "  for i in range(10):\n",
    "    if(tf.math.greater_equal(jacc, 0.5)):\n",
    "      number += 1\n",
    "  \n",
    "  print(number)\n",
    "  print(number * 2) # Tensor(\"mul:0\", shape=(), dtype=int32)\n",
    "  \n",
    "  # number을 이용해서 여러 연산을 하려고 합니다. \n",
    "  # 그런데 Tensor 형태라서 제한이 있습니다. 어떻게 해야하나요?\n",
    "  for k in range(number * 2):\n",
    "    print(k) # Tensor(\"placeholder:0\", shape=(), dtype=int32)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1570431478885,
     "user": {
      "displayName": "조휘용",
      "photoUrl": "",
      "userId": "03176435450859375087"
     },
     "user_tz": -540
    },
    "id": "1QMpImixAYoK",
    "outputId": "843d1ea6-9a67-47c1-a643-67e1b805e15c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"cond_19/Identity:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test():\n",
    "  number = 0\n",
    "  \n",
    "  for i in range(10):\n",
    "    for j in range(2):\n",
    "      if(tf.math.greater_equal(1., 0.5)):\n",
    "        number += 1\n",
    "        \n",
    "  print(number)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMKV_1U_vKGg"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test():\n",
    "  a = tf.constant([1, 2, 3, 4])\n",
    "  \n",
    "  matches = []\n",
    "  # pred_confs.shsape, pred_locs.shape, len(actual_locs), len(actual_labels)\n",
    "  # (938, 21) (938, 4) 2 2\n",
    "  print('In Matcher1!===============================')\n",
    "  for _ in range(10):\n",
    "      matches.append(999) # len is 938\n",
    "  \n",
    "  loss_conf_cnt = 0\n",
    "  neg_pos = 5\n",
    "  reduce_max_list = []\n",
    "  for i in range(10):\n",
    "    reduce_max_list.append(tf.reduce_max(a))\n",
    "    loss_conf_cnt += 1\n",
    "    \n",
    "  size = tf.math.minimum(2, loss_conf_cnt)\n",
    "  \n",
    "  # TopKV2(values=<tf.Tensor 'TopKV2:0' shape=(2,) dtype=int32>, \n",
    "  # indices=<tf.Tensor 'TopKV2:1' shape=(2,) dtype=int32>)\n",
    "  test_top_k = tf.math.top_k(reduce_max_list, size)\n",
    "  \n",
    "  # test_top_k[1].get_shape()[0] : 2\n",
    "  for i in range(test_top_k[1].get_shape()[0]):\n",
    "    temp_index = test_top_k[1][i]\n",
    "    print(temp_index) # Tensor(\"strided_slice:0\", shape=(), dtype=int32)\n",
    "    \n",
    "    print(tf.gather(matches, temp_index))\n",
    "    \n",
    "    \n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UciUuC7wwnVR"
   },
   "outputs": [],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxAqUZHSByJN"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test():\n",
    "  \n",
    "  tf.print('aaaa')\n",
    "  a = tf.constant(938)\n",
    "  b = tf.multiply(a, 2)\n",
    "  test()\n",
    "  \n",
    "  if(a > b):\n",
    "    tf.print('aa')\n",
    "  else:\n",
    "    tf.print('bb')\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lz3VrnlIyiJF"
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "tf.where(True, )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "current_convert.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "keras_study",
   "language": "python",
   "name": "keras_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
